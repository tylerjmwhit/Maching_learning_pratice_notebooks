{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerjmwhit/Maching_learning_pratice_notebooks/blob/main/Week14assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eBjy5x8fMKe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers, models\n",
        "from tensorflow.keras.datasets.mnist import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "AC8EN5rvefns",
        "outputId": "eda0189f-f9c0-42e3-fe9d-1a8c636733c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 11.8 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "from yfinance import ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JDXYHgBiVi5"
      },
      "source": [
        "Exercise 1:\n",
        "\n",
        "Train an RNN on the stock data that we did in an earlier lab. Try to predict the closed column with an input sequence of 10, 20 and 50 previous closed values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mjeWBfvRfg_9",
        "outputId": "28097ae9-288b-4a71-dca4-379513f1e403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date        Open        High         Low       Close       Volume  \\\n",
              "0    1999-01-22    0.401824    0.448464    0.356379    0.376709  271468800.0   \n",
              "1    1999-01-25    0.406607    0.420958    0.376709    0.416175   51048000.0   \n",
              "2    1999-01-26    0.420958    0.429329    0.377905    0.383885   34320000.0   \n",
              "3    1999-01-27    0.385081    0.394649    0.363554    0.382690   24436800.0   \n",
              "4    1999-01-28    0.382690    0.385081    0.379101    0.381494   22752000.0   \n",
              "...         ...         ...         ...         ...         ...          ...   \n",
              "5873 2022-05-23  162.740005  169.149994  161.789993  168.979996   63988900.0   \n",
              "5874 2022-05-24  165.100006  165.970001  157.800003  161.539993   58855000.0   \n",
              "5875 2022-05-25  160.199997  171.110001  160.000000  169.750000   78113200.0   \n",
              "5876 2022-05-26  160.360001  180.919998  160.220001  178.509995   99657500.0   \n",
              "5877 2022-05-27  181.860001  188.809998  181.000000  188.110001   73770700.0   \n",
              "\n",
              "      Dividends  Stock Splits  \n",
              "0           0.0           0.0  \n",
              "1           0.0           0.0  \n",
              "2           0.0           0.0  \n",
              "3           0.0           0.0  \n",
              "4           0.0           0.0  \n",
              "...         ...           ...  \n",
              "5873        0.0           0.0  \n",
              "5874        0.0           0.0  \n",
              "5875        0.0           0.0  \n",
              "5876        0.0           0.0  \n",
              "5877        0.0           0.0  \n",
              "\n",
              "[5878 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6a175e0-d214-44a2-8232-61593d9817a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999-01-22</td>\n",
              "      <td>0.401824</td>\n",
              "      <td>0.448464</td>\n",
              "      <td>0.356379</td>\n",
              "      <td>0.376709</td>\n",
              "      <td>271468800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999-01-25</td>\n",
              "      <td>0.406607</td>\n",
              "      <td>0.420958</td>\n",
              "      <td>0.376709</td>\n",
              "      <td>0.416175</td>\n",
              "      <td>51048000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999-01-26</td>\n",
              "      <td>0.420958</td>\n",
              "      <td>0.429329</td>\n",
              "      <td>0.377905</td>\n",
              "      <td>0.383885</td>\n",
              "      <td>34320000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1999-01-27</td>\n",
              "      <td>0.385081</td>\n",
              "      <td>0.394649</td>\n",
              "      <td>0.363554</td>\n",
              "      <td>0.382690</td>\n",
              "      <td>24436800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1999-01-28</td>\n",
              "      <td>0.382690</td>\n",
              "      <td>0.385081</td>\n",
              "      <td>0.379101</td>\n",
              "      <td>0.381494</td>\n",
              "      <td>22752000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5873</th>\n",
              "      <td>2022-05-23</td>\n",
              "      <td>162.740005</td>\n",
              "      <td>169.149994</td>\n",
              "      <td>161.789993</td>\n",
              "      <td>168.979996</td>\n",
              "      <td>63988900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5874</th>\n",
              "      <td>2022-05-24</td>\n",
              "      <td>165.100006</td>\n",
              "      <td>165.970001</td>\n",
              "      <td>157.800003</td>\n",
              "      <td>161.539993</td>\n",
              "      <td>58855000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5875</th>\n",
              "      <td>2022-05-25</td>\n",
              "      <td>160.199997</td>\n",
              "      <td>171.110001</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>169.750000</td>\n",
              "      <td>78113200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5876</th>\n",
              "      <td>2022-05-26</td>\n",
              "      <td>160.360001</td>\n",
              "      <td>180.919998</td>\n",
              "      <td>160.220001</td>\n",
              "      <td>178.509995</td>\n",
              "      <td>99657500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5877</th>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>181.860001</td>\n",
              "      <td>188.809998</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>188.110001</td>\n",
              "      <td>73770700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5878 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6a175e0-d214-44a2-8232-61593d9817a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6a175e0-d214-44a2-8232-61593d9817a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6a175e0-d214-44a2-8232-61593d9817a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tk = ticker.Ticker('NVDA')\n",
        "df = tk.history(period = 'max').reset_index()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBdPvoVHgqr5"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(axis = 0)\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWjebK_ogDyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd47fc4-7792-4d8e-c81d-23ba9afb5497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_1 (GRU)                 (None, 50)                8400      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,604\n",
            "Trainable params: 8,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(20,4)))\n",
        "model.add(layers.GRU(50))\n",
        "model.add(layers.Dense(4, activation=None))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK5Lmx8agMuU"
      },
      "outputs": [],
      "source": [
        "cols = ['Open','High','Low','Close']\n",
        "inputs, outputs = [], []\n",
        "for i in range(len(df)-20):\n",
        "  inputs.append(df.loc[i:i+19, cols])\n",
        "  outputs.append(df.loc[i+20, cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsWdRBavgVb2",
        "outputId": "821551d9-7bb5-408d-c085-ceb8fe40c23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "184/184 [==============================] - 7s 4ms/step - loss: 3240.1736\n",
            "Epoch 2/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 2868.3792\n",
            "Epoch 3/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 2573.7046\n",
            "Epoch 4/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 2321.0793\n",
            "Epoch 5/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 2109.6902\n",
            "Epoch 6/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1922.5427\n",
            "Epoch 7/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1770.0142\n",
            "Epoch 8/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1632.0077\n",
            "Epoch 9/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1506.4921\n",
            "Epoch 10/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1390.5499\n",
            "Epoch 11/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1281.7233\n",
            "Epoch 12/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1179.9772\n",
            "Epoch 13/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1085.2915\n",
            "Epoch 14/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 996.9630\n",
            "Epoch 15/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 915.4559\n",
            "Epoch 16/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 839.9221\n",
            "Epoch 17/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 770.4989\n",
            "Epoch 18/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 706.7355\n",
            "Epoch 19/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 648.4335\n",
            "Epoch 20/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 595.0025\n",
            "Epoch 21/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 546.4211\n",
            "Epoch 22/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 502.6555\n",
            "Epoch 23/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 462.8579\n",
            "Epoch 24/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 425.1814\n",
            "Epoch 25/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 390.0093\n",
            "Epoch 26/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 356.6013\n",
            "Epoch 27/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 324.0247\n",
            "Epoch 28/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 296.8463\n",
            "Epoch 29/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 275.3808\n",
            "Epoch 30/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 248.5712\n",
            "Epoch 31/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 229.1202\n",
            "Epoch 32/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 206.6802\n",
            "Epoch 33/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 188.5014\n",
            "Epoch 34/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 172.0348\n",
            "Epoch 35/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 157.4728\n",
            "Epoch 36/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 143.4785\n",
            "Epoch 37/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 130.7356\n",
            "Epoch 38/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 118.4313\n",
            "Epoch 39/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 108.9228\n",
            "Epoch 40/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 100.2537\n",
            "Epoch 41/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 111.9017\n",
            "Epoch 42/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 100.6657\n",
            "Epoch 43/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 92.4128\n",
            "Epoch 44/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 83.1353\n",
            "Epoch 45/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 75.4930\n",
            "Epoch 46/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 87.2412\n",
            "Epoch 47/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 80.4974\n",
            "Epoch 48/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 89.5309\n",
            "Epoch 49/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 80.6445\n",
            "Epoch 50/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 70.2909\n",
            "Epoch 51/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 65.2813\n",
            "Epoch 52/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 58.7232\n",
            "Epoch 53/70\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 73.3381\n",
            "Epoch 54/70\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 71.8438\n",
            "Epoch 55/70\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 64.5000\n",
            "Epoch 56/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 55.9254\n",
            "Epoch 57/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 50.9322\n",
            "Epoch 58/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 56.9658\n",
            "Epoch 59/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 56.6579\n",
            "Epoch 60/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 48.7893\n",
            "Epoch 61/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 47.3579\n",
            "Epoch 62/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 55.4656\n",
            "Epoch 63/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 49.5153\n",
            "Epoch 64/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 43.3591\n",
            "Epoch 65/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 39.8537\n",
            "Epoch 66/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 34.9400\n",
            "Epoch 67/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 30.0801\n",
            "Epoch 68/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 29.6776\n",
            "Epoch 69/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 27.6025\n",
            "Epoch 70/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 22.4363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cdf97d050>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.compile(optimizer='adam',loss='mse')\n",
        "model.fit(np.array(inputs).astype(float), np.array(outputs).astype(float), epochs=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "pqx02DuQjiTh",
        "outputId": "535d263b-5e99-46d9-f739-0c0d70609d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Open      High       Low     Close\n",
              "100  0.330069  0.344420  0.325286  0.334853\n",
              "101  0.332461  0.337245  0.325286  0.325286\n",
              "102  0.327678  0.327678  0.313327  0.313327\n",
              "103  0.322894  0.330069  0.314223  0.330069\n",
              "104  0.330069  0.330069  0.316914  0.324090\n",
              "105  0.320502  0.330069  0.316914  0.330069\n",
              "106  0.332461  0.332461  0.320502  0.322894\n",
              "107  0.320502  0.331265  0.320502  0.327678\n",
              "108  0.338441  0.338441  0.325286  0.332461\n",
              "109  0.337245  0.340833  0.332461  0.336049\n",
              "110  0.346812  0.365947  0.339637  0.365947"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cdb3268-4461-48ab-bd3f-5f814c934b5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.330069</td>\n",
              "      <td>0.344420</td>\n",
              "      <td>0.325286</td>\n",
              "      <td>0.334853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.332461</td>\n",
              "      <td>0.337245</td>\n",
              "      <td>0.325286</td>\n",
              "      <td>0.325286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.327678</td>\n",
              "      <td>0.327678</td>\n",
              "      <td>0.313327</td>\n",
              "      <td>0.313327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.322894</td>\n",
              "      <td>0.330069</td>\n",
              "      <td>0.314223</td>\n",
              "      <td>0.330069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.330069</td>\n",
              "      <td>0.330069</td>\n",
              "      <td>0.316914</td>\n",
              "      <td>0.324090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.320502</td>\n",
              "      <td>0.330069</td>\n",
              "      <td>0.316914</td>\n",
              "      <td>0.330069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.332461</td>\n",
              "      <td>0.332461</td>\n",
              "      <td>0.320502</td>\n",
              "      <td>0.322894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0.320502</td>\n",
              "      <td>0.331265</td>\n",
              "      <td>0.320502</td>\n",
              "      <td>0.327678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.338441</td>\n",
              "      <td>0.338441</td>\n",
              "      <td>0.325286</td>\n",
              "      <td>0.332461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.337245</td>\n",
              "      <td>0.340833</td>\n",
              "      <td>0.332461</td>\n",
              "      <td>0.336049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.346812</td>\n",
              "      <td>0.365947</td>\n",
              "      <td>0.339637</td>\n",
              "      <td>0.365947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cdb3268-4461-48ab-bd3f-5f814c934b5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cdb3268-4461-48ab-bd3f-5f814c934b5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cdb3268-4461-48ab-bd3f-5f814c934b5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "input_10, input_20 = [] , []\n",
        "input_10 = df.loc[100:110 , cols]\n",
        "input_20 = df.loc[120:139, cols]\n",
        "input_pad = np.zeros((9,4))\n",
        "input_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijTKVq1ulMfs",
        "outputId": "0e40e7c2-8fa1-4484-a7db-e899e64dfbfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3300694 , 0.34442024, 0.32528611, 0.3348527 ],\n",
              "       [0.33246102, 0.33724524, 0.32528606, 0.32528606],\n",
              "       [0.32767774, 0.32767774, 0.3133269 , 0.3133269 ],\n",
              "       [0.32289441, 0.33006936, 0.31422327, 0.33006936],\n",
              "       [0.33006934, 0.33006934, 0.31691433, 0.32409021],\n",
              "       [0.32050182, 0.33006936, 0.31691435, 0.33006936],\n",
              "       [0.3324611 , 0.3324611 , 0.32050189, 0.32289448],\n",
              "       [0.32050184, 0.33126522, 0.32050184, 0.32767773],\n",
              "       [0.33844105, 0.33844105, 0.32528604, 0.332461  ],\n",
              "       [0.33724527, 0.34083274, 0.33246105, 0.33604851],\n",
              "       [0.34681191, 0.36594698, 0.33963695, 0.36594698]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_10 = np.array(input_10)\n",
        "input_20 = np.array(input_20)\n",
        "input_10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZWpPNazmRg0",
        "outputId": "6c9ec564-a1b7-4980-8faf-d269ee292742"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "input_10 = np.append(input_pad, input_10)\n",
        "input_10.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6WodtFrnNKI"
      },
      "outputs": [],
      "source": [
        "pred_10 = model.predict(input_10.reshape(1,20,4))\n",
        "pred_20 = model.predict(input_20.reshape(1,20,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tJ5xrxPnxjv",
        "outputId": "19e55a8b-46ad-4b66-ff98-5f0545bb2abf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Open     0.365947\n",
              "High     0.365947\n",
              "Low      0.327678\n",
              "Close    0.346812\n",
              "Name: 111, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "actual_10 = df.loc[111,cols]\n",
        "actual_20 = df.loc[140,cols]\n",
        "actual_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffd_y9YUoJlV",
        "outputId": "8094e062-f16f-44e4-f381-d6d10bf687f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.31739092 0.2754035  0.30029488 0.33326292]] [0.3659468647625153 0.3659468647625153 0.3276776409055401\n",
            " 0.34681180119514465]\n",
            "[[0.4069724  0.38098    0.3895378  0.46078348]] [0.420957747985286 0.4496594343938769 0.41856611414095746\n",
            " 0.4388970136642456]\n"
          ]
        }
      ],
      "source": [
        "print(pred_10,np.array(actual_10))\n",
        "print(pred_20,np.array(actual_20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVlB5ByaonMT"
      },
      "source": [
        "Overall this model was not very good at predicting data. However with some fine tuning I might be able to get a more accurate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvR5msgQoylc"
      },
      "source": [
        "Excersie 2:\n",
        "Generally an RNN accepts a sequence of vectors as an input.\n",
        "A grayscale image can also be considered a sequence of rows of pixels.\n",
        "Train two RNN on the MNIST dataset, where one uses an LSTM cell and the other a GRU cell. Run the necessary steps to compare the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRjs6XA8o4-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b886a3-8290-42fe-d207-b590651363d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OzzDxrgpeZk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(y_train.reshape(-1,1))\n",
        "y_train = enc.transform(y_train.reshape(-1,1)).toarray()\n",
        "y_test = enc.transform(y_test.reshape(-1,1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sN-dSam0LJaS",
        "outputId": "af2141c8-891f-4183-b04d-60e74e8978c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8cc659d1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh0T0RQepVgU"
      },
      "outputs": [],
      "source": [
        "from keras.backend import softmax\n",
        "model_gru = models.Sequential()\n",
        "model_gru.add(layers.InputLayer(input_shape=(28,28)))\n",
        "model_gru.add(layers.GRU(50))\n",
        "model_gru.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76GR6Um2pXUn"
      },
      "outputs": [],
      "source": [
        "model_lstm = models.Sequential()\n",
        "model_lstm.add(layers.InputLayer(input_shape=(28,28)))\n",
        "model_lstm.add(layers.LSTM(50))\n",
        "model_lstm.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ6IWzr0rmHY",
        "outputId": "1032b8bc-f839-458c-8d39-8df3f66a4dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.9154\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6110\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5295\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4990\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4666\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4502\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4299\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4096\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4054\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3982\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3873\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3822\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3733\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3671\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3570\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3480\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3405\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3264\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3070\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cf0f90390>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model_gru.compile(optimizer='adam',loss='CategoricalCrossentropy')\n",
        "model_gru.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrxfZiTWrnqi",
        "outputId": "3f06fa97-3cca-41e1-acfa-4f06fdd30baa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 7523491238973769990\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14465892352\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 13774831120909551066\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzwjO243ujbI",
        "outputId": "d37115a3-35ff-4b41-f03b-6c355ecdae5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7402\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4446\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3785\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3503\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3227\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3012\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2879\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2750\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2645\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2567\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2515\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2409\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2388\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2297\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2221\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2174\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2134\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2084\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2041\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2019\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1994\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1988\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1954\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1883\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1838\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1851\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1876\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1818\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1815\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1771\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1755\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1727\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1696\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1683\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1666\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1639\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1624\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1586\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1593\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1558\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1565\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1517\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1517\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1487\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1490\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1508\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1481\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1445\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1461\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1419\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1393\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1451\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1389\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1373\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1360\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1351\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1406\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1351\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1297\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1306\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1317\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1305\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1308\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1325\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1315\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1274\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1236\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1273\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1277\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1243\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1264\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1216\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1238\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1209\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1249\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1192\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1184\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1177\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1179\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1186\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1179\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1134\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1118\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1142\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1111\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1097\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1164\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1087\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1129\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1119\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1093\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1111\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1127\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1101\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1048\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1041\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1056\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1071\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1055\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1064\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cf0ece610>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model_lstm.compile(optimizer='adam',loss='CategoricalCrossentropy')\n",
        "model_lstm.fit(x_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w1ioYeXumWA"
      },
      "outputs": [],
      "source": [
        "preds_gru = model_gru.predict(x_test)\n",
        "preds_lstm = model_lstm.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmbrQKciy57T"
      },
      "outputs": [],
      "source": [
        "preds_gru = enc.inverse_transform(preds_gru)\n",
        "preds_lstm = enc.inverse_transform(preds_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYd2zXTcu-WV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9fPSDxOvVcz",
        "outputId": "8c023127-0773-4a6d-d22d-c596df276745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report + confusion matrix for GRU model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89       980\n",
            "           1       0.96      0.97      0.96      1135\n",
            "           2       0.91      0.89      0.90      1032\n",
            "           3       0.86      0.89      0.88      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.90      0.88      0.89       892\n",
            "           6       0.89      0.97      0.93       958\n",
            "           7       0.89      0.88      0.89      1028\n",
            "           8       0.83      0.82      0.83       974\n",
            "           9       0.85      0.81      0.83      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "[[ 878    0    3    7    1    1   14    0   76    0]\n",
            " [   0 1099    6    3    9    4   10    1    2    1]\n",
            " [   7    5  917   42    9    6   29    5   11    1]\n",
            " [   1    2   34  901    2   34    1   19    8    8]\n",
            " [   4    8   14    3  825    4    8   13   20   83]\n",
            " [   2    3    9   44    3  789   21    5   14    2]\n",
            " [   9    0    4    0    1    8  929    0    7    0]\n",
            " [   0   18   17    7   23    7    0  907    1   48]\n",
            " [  89    3    4   16    9   14   32    0  800    7]\n",
            " [   0    6    1   22   56   12    0   69   23  820]]\n"
          ]
        }
      ],
      "source": [
        "print(\"classification report + confusion matrix for GRU model\")\n",
        "print(classification_report(enc.inverse_transform(y_test),preds_gru))\n",
        "print(confusion_matrix(enc.inverse_transform(y_test),preds_gru))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tTGoupZwBdh",
        "outputId": "73b1557b-0d3f-49ad-ad17-528c27417cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report + confusion matrix for LSTM model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       980\n",
            "           1       0.98      0.98      0.98      1135\n",
            "           2       0.94      0.95      0.94      1032\n",
            "           3       0.91      0.94      0.93      1010\n",
            "           4       0.90      0.92      0.91       982\n",
            "           5       0.94      0.89      0.92       892\n",
            "           6       0.97      0.97      0.97       958\n",
            "           7       0.92      0.92      0.92      1028\n",
            "           8       0.94      0.92      0.93       974\n",
            "           9       0.89      0.87      0.88      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "[[ 959    0    3    2    1    2    3    0   10    0]\n",
            " [   0 1116    7    1    2    2    2    1    2    2]\n",
            " [   3    5  981   11    5    4    4    7    9    3]\n",
            " [   1    2   19  948    0   24    0    5    4    7]\n",
            " [   1    2    6    0  900    1    3   20    8   41]\n",
            " [   2    0    4   59    3  797    3    5   11    8]\n",
            " [   3    1    9    0    7    3  929    0    6    0]\n",
            " [   0    6    6    2   21    4    0  948    0   41]\n",
            " [  31    3    9    3    5    7   12    1  896    7]\n",
            " [   0    5    4   13   54    4    0   43   12  874]]\n"
          ]
        }
      ],
      "source": [
        "print(\"classification report + confusion matrix for LSTM model\")\n",
        "print(classification_report(enc.inverse_transform(y_test),preds_lstm))\n",
        "print(confusion_matrix(enc.inverse_transform(y_test),preds_lstm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-chEcIRQzX-P"
      },
      "source": [
        "It looks like the LSTM version was able to about a 4% higher f1-score compared to the GRU version. This makes sense since the LSTM version has a longer \"memory\" so should be able to interpet the 28 lines of the array in a more significant way. More epochs on both of these models might help improve their predicition capabilites"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiviNYGlkqOwSZ+aJKka+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}