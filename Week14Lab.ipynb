{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG/RxAc1pJ3wPbD07HOIWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerjmwhit/Maching_learning_pratice_notebooks/blob/main/Week14Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erqwXQDmMn4K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import keras\n",
        "from keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpUfBoKmNPLO",
        "outputId": "2f2d5a47-5111-4984-e92b-c2624093069c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train an RNN that predicts the next character from the previous 20 letters of a corpus of text, e.g. shakespeare's sonnets (in week13 folder). That is create a classification RNN where the input of some string is a one hot encoded string of length 20 to predict the one hot encoded target of the 21st string element."
      ],
      "metadata": {
        "id": "CHPrA3coWlCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/EE485_dataSets/sonnets3.txt') as f:\n",
        "    lines = [x.replace('\\n', ' ') for x in f.read()]\n",
        "res1 = \"\"\n",
        "for i in lines:\n",
        "    if i.isalpha() or i.isspace():\n",
        "        res1 += str(i)\n",
        "res1 = res1.lower()"
      ],
      "metadata": {
        "id": "cZZR4J6WNcYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = [i for i in res1]\n",
        "df = pd.DataFrame(res)\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(df)\n",
        "enc.categories_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFwRO9otS626",
        "outputId": "f9863b4e-5f06-4862-e7ff-764757c2243e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm',\n",
              "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
              "       dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mysonnet = enc.transform(df).toarray()\n",
        "df = pd.DataFrame(mysonnet.astype(int), columns = enc.categories_)"
      ],
      "metadata": {
        "id": "9sAwvSs3WulU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, outputs = [], []\n",
        "for i in range(len(df)-20):\n",
        "  inputs.append(df.loc[i:i+19])\n",
        "  outputs.append(df.loc[i+20])"
      ],
      "metadata": {
        "id": "33b_4KYAWt3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[:1])\n",
        "print(outputs[1])"
      ],
      "metadata": {
        "id": "6lJ9V791dFab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)"
      ],
      "metadata": {
        "id": "K8xxeVWPwphX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(inputs).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW5rhPsJeEtV",
        "outputId": "5fbeb8ec-93e0-4d01-aab6-fa441e0b2743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42362, 20, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(20,26)))\n",
        "model.add(layers.GRU(250, dropout=.1, return_sequences=True))\n",
        "model.add(layers.GRU(100, dropout =.1))\n",
        "model.add(layers.Dense(26, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffQPgBVYS6xD",
        "outputId": "dc8c62ba-5fe3-4155-8526-2b636da4b68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_19 (GRU)                (None, 20, 250)           208500    \n",
            "                                                                 \n",
            " gru_20 (GRU)                (None, 100)               105600    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 26)                2626      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 316,726\n",
            "Trainable params: 316,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(outputs).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hdKCh3ldthM",
        "outputId": "aec71b3c-7e9e-4f08-f6dc-bad80131fae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42362, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "model.fit(inputs, outputs, epochs=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7n9w23PVzUm",
        "outputId": "3f97895f-501e-4fc3-a289-61fc3023dbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "1324/1324 [==============================] - 113s 83ms/step - loss: 2.2617\n",
            "Epoch 2/120\n",
            "1324/1324 [==============================] - 109s 82ms/step - loss: 1.9733\n",
            "Epoch 3/120\n",
            "1324/1324 [==============================] - 108s 82ms/step - loss: 1.8597\n",
            "Epoch 4/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.7958\n",
            "Epoch 5/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.7415\n",
            "Epoch 6/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.6996\n",
            "Epoch 7/120\n",
            "1324/1324 [==============================] - 108s 82ms/step - loss: 1.6636\n",
            "Epoch 8/120\n",
            "1324/1324 [==============================] - 105s 80ms/step - loss: 1.6170\n",
            "Epoch 9/120\n",
            "1324/1324 [==============================] - 105s 80ms/step - loss: 1.5835\n",
            "Epoch 10/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.5554\n",
            "Epoch 11/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.5231\n",
            "Epoch 12/120\n",
            "1324/1324 [==============================] - 108s 81ms/step - loss: 1.4938\n",
            "Epoch 13/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.4670\n",
            "Epoch 14/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.4366\n",
            "Epoch 15/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.4114\n",
            "Epoch 16/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.3822\n",
            "Epoch 17/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.3588\n",
            "Epoch 18/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.3392\n",
            "Epoch 19/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.3208\n",
            "Epoch 20/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.2922\n",
            "Epoch 21/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.2770\n",
            "Epoch 22/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.2616\n",
            "Epoch 23/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.2420\n",
            "Epoch 24/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.2186\n",
            "Epoch 25/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.2108\n",
            "Epoch 26/120\n",
            "1324/1324 [==============================] - 107s 80ms/step - loss: 1.1968\n",
            "Epoch 27/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 1.1838\n",
            "Epoch 28/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 1.1742\n",
            "Epoch 29/120\n",
            "1324/1324 [==============================] - 105s 80ms/step - loss: 1.1632\n",
            "Epoch 30/120\n",
            "1324/1324 [==============================] - 105s 79ms/step - loss: 1.1510\n",
            "Epoch 31/120\n",
            "1324/1324 [==============================] - 105s 80ms/step - loss: 1.1369\n",
            "Epoch 32/120\n",
            "1324/1324 [==============================] - 108s 82ms/step - loss: 1.1331\n",
            "Epoch 33/120\n",
            "1324/1324 [==============================] - 113s 86ms/step - loss: 1.1197\n",
            "Epoch 34/120\n",
            "1324/1324 [==============================] - 109s 83ms/step - loss: 1.1140\n",
            "Epoch 35/120\n",
            "1324/1324 [==============================] - 113s 86ms/step - loss: 1.1073\n",
            "Epoch 36/120\n",
            "1324/1324 [==============================] - 111s 84ms/step - loss: 1.0940\n",
            "Epoch 37/120\n",
            "1324/1324 [==============================] - 116s 87ms/step - loss: 1.0795\n",
            "Epoch 38/120\n",
            "1324/1324 [==============================] - 110s 83ms/step - loss: 1.0736\n",
            "Epoch 39/120\n",
            "1324/1324 [==============================] - 112s 85ms/step - loss: 1.0640\n",
            "Epoch 40/120\n",
            "1324/1324 [==============================] - 112s 85ms/step - loss: 1.0604\n",
            "Epoch 41/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 1.0566\n",
            "Epoch 42/120\n",
            "1324/1324 [==============================] - 115s 87ms/step - loss: 1.0530\n",
            "Epoch 43/120\n",
            "1324/1324 [==============================] - 108s 82ms/step - loss: 1.0432\n",
            "Epoch 44/120\n",
            "1324/1324 [==============================] - 119s 90ms/step - loss: 1.0408\n",
            "Epoch 45/120\n",
            "1324/1324 [==============================] - 119s 90ms/step - loss: 1.0272\n",
            "Epoch 46/120\n",
            "1324/1324 [==============================] - 118s 89ms/step - loss: 1.0281\n",
            "Epoch 47/120\n",
            "1324/1324 [==============================] - 115s 87ms/step - loss: 1.0174\n",
            "Epoch 48/120\n",
            "1324/1324 [==============================] - 116s 87ms/step - loss: 1.0151\n",
            "Epoch 49/120\n",
            "1324/1324 [==============================] - 115s 87ms/step - loss: 1.0205\n",
            "Epoch 50/120\n",
            "1324/1324 [==============================] - 116s 88ms/step - loss: 1.0107\n",
            "Epoch 51/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 1.0002\n",
            "Epoch 52/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 0.9933\n",
            "Epoch 53/120\n",
            "1324/1324 [==============================] - 116s 87ms/step - loss: 0.9864\n",
            "Epoch 54/120\n",
            "1324/1324 [==============================] - 109s 82ms/step - loss: 0.9861\n",
            "Epoch 55/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 0.9799\n",
            "Epoch 56/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 0.9732\n",
            "Epoch 57/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 0.9701\n",
            "Epoch 58/120\n",
            "1324/1324 [==============================] - 106s 80ms/step - loss: 0.9622\n",
            "Epoch 59/120\n",
            "1324/1324 [==============================] - 107s 80ms/step - loss: 0.9662\n",
            "Epoch 60/120\n",
            "1324/1324 [==============================] - 107s 81ms/step - loss: 0.9636\n",
            "Epoch 61/120\n",
            "1324/1324 [==============================] - 109s 82ms/step - loss: 0.9542\n",
            "Epoch 62/120\n",
            "1324/1324 [==============================] - 112s 85ms/step - loss: 0.9593\n",
            "Epoch 63/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 0.9520\n",
            "Epoch 64/120\n",
            "1324/1324 [==============================] - 111s 84ms/step - loss: 0.9486\n",
            "Epoch 65/120\n",
            "1324/1324 [==============================] - 113s 85ms/step - loss: 0.9365\n",
            "Epoch 66/120\n",
            "1324/1324 [==============================] - 111s 84ms/step - loss: 0.9359\n",
            "Epoch 67/120\n",
            "1324/1324 [==============================] - 112s 85ms/step - loss: 0.9316\n",
            "Epoch 68/120\n",
            "1324/1324 [==============================] - 111s 84ms/step - loss: 0.9264\n",
            "Epoch 69/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 0.9355\n",
            "Epoch 70/120\n",
            "1324/1324 [==============================] - 109s 82ms/step - loss: 0.9214\n",
            "Epoch 71/120\n",
            "1324/1324 [==============================] - 114s 86ms/step - loss: 0.9216\n",
            "Epoch 72/120\n",
            "1324/1324 [==============================] - 110s 83ms/step - loss: 0.9146\n",
            "Epoch 73/120\n",
            "1324/1324 [==============================] - 112s 85ms/step - loss: 0.9166\n",
            "Epoch 74/120\n",
            "1324/1324 [==============================] - 108s 82ms/step - loss: 0.9095\n",
            "Epoch 75/120\n",
            "1324/1324 [==============================] - 115s 87ms/step - loss: 0.9063\n",
            "Epoch 76/120\n",
            "1324/1324 [==============================] - 113s 85ms/step - loss: 0.9032\n",
            "Epoch 77/120\n",
            " 552/1324 [===========>..................] - ETA: 1:05 - loss: 0.8810"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = 'now is the winter cold dew forms'\n",
        "sample_string = [i for i in sample_string]\n",
        "sample_df = pd.DataFrame(sample_string)\n",
        "sample_string = enc.transform(sample_df).toarray()"
      ],
      "metadata": {
        "id": "ilXFtJMdfJfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = np.array(sample_string)\n",
        "sample_string.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqid04HJibk9",
        "outputId": "0bc969c2-bb65-436a-95c4-cf52895811ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = np.array(inputs[0]).reshape(-1,20,26)\n",
        "print(sample.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F1RsFy0w-aL",
        "outputId": "6262441a-2f78-4b38-eb61-6f8afec81909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 20, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  preds = model.predict((sample_string[-20:]).reshape(-1,20,26))\n",
        "  sample_string = np.append(sample_string,preds,axis=0)"
      ],
      "metadata": {
        "id": "s-H9g4URhPur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gensonnet = enc.inverse_transform(sample_string)\n",
        "gensonnet.reshape(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcRn6rtbhwQU",
        "outputId": "e6118cee-8d02-4b34-a792-56119c5d8229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['n', 'o', 'w', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'w', 'i',\n",
              "        'n', 't', 'e', 'r', ' ', 'c', 'o', 'l', 'd', ' ', 'd', 'e', 'w',\n",
              "        ' ', 'f', 'o', 'r', 'm', 's', 't', 'i', 't', ' ', 't', 'h', 'a',\n",
              "        'm', 'e', 's', ' ', 'a', 'r', 'e', ' ', 't', 'i', 'e', 's', ' ',\n",
              "        ' ', 'o', ' ', 'e', ' ', 'o', ' ', 't', 'i', 'n', 'e', ' ', ' ',\n",
              "        'n', ' ', 't', 'e', 'n', 'e', 't', 'o', 'n', 'e', 't', 'i', 'e',\n",
              "        ' ', 't', 'i', 'e', 'e', 's', ' ', 'b', 'e', 't', 't', ' ', 'n',\n",
              "        'o', 't', ' ', 't', 'o', ' ', 's', 'e', 's', ' ', ' ', 'f', 'o',\n",
              "        'r', ' ', 'm', 'o', ' ', 'r', 'o', 'n', 'e', ' ', 'i', 'n', ' ',\n",
              "        's', 'e', 'n', 'd', 'e', 'r', ' ', 's', 'o', 'r', 's', 'e', 'r',\n",
              "        ' ', 's']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gensonnet = gensonnet.flatten().flatten()\n",
        "print(gensonnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NomT-USFuIX_",
        "outputId": "61d0b15a-85ca-48d9-b175-7deaac6f637c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n' 'o' 'w' ' ' 'i' 's' ' ' 't' 'h' 'e' ' ' 'w' 'i' 'n' 't' 'e' 'r' ' '\n",
            " 'c' 'o' 'l' 'd' ' ' 'd' 'e' 'w' ' ' 'f' 'o' 'r' 'm' 's' 't' 'i' 't' ' '\n",
            " 't' 'h' 'a' 'm' 'e' 's' ' ' 'a' 'r' 'e' ' ' 't' 'i' 'e' 's' ' ' ' ' 'o'\n",
            " ' ' 'e' ' ' 'o' ' ' 't' 'i' 'n' 'e' ' ' ' ' 'n' ' ' 't' 'e' 'n' 'e' 't'\n",
            " 'o' 'n' 'e' 't' 'i' 'e' ' ' 't' 'i' 'e' 'e' 's' ' ' 'b' 'e' 't' 't' ' '\n",
            " 'n' 'o' 't' ' ' 't' 'o' ' ' 's' 'e' 's' ' ' ' ' 'f' 'o' 'r' ' ' 'm' 'o'\n",
            " ' ' 'r' 'o' 'n' 'e' ' ' 'i' 'n' ' ' 's' 'e' 'n' 'd' 'e' 'r' ' ' 's' 'o'\n",
            " 'r' 's' 'e' 'r' ' ' 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = \"\"\n",
        "for i in gensonnet:\n",
        "    str1 += i\n",
        "print(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50zNvuntv9sz",
        "outputId": "e2a3055e-2746-4c47-a87c-162e68f1559e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['now is the winter cold dew formst ceme alere trese tht a e ooth res out o ean sime e t tut ones  o  th sime aoth some for tus iut ri']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "uCZzf835JExF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str2 = \"\"\n",
        "for i in gensonnet:\n",
        "    str2 += i\n",
        "print(str2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__6OU0NoIZMH",
        "outputId": "4bb82605-3045-49dd-d618-99229a2b3c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now is the winter cold dew formstit thames are ties  o e o tine  n tenetonetie tiees bett not to ses  for mo rone in sender sorser s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is pretty much jibbersh\n",
        "I might get better results if I had a deeper network or more epochs"
      ],
      "metadata": {
        "id": "7LwVkzW1zTjP"
      }
    }
  ]
}